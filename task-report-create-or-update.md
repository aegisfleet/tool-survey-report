# AI調査エージェント指示書

## 概要

このドキュメントは、AIが調査レポートを作成する際の指示書です。`templates/template.md`のテンプレートを基に、指定されたツールについて包括的な調査を行い、レポートを作成する。

> **重要**: テンプレート（`templates/template.md`）は常に最新の状態に更新されています。レポート作成・更新時は必ずテンプレートを確認し、セクション構成・形式・記載ガイドラインに厳密に従ってください。

## 調査優先度

レポートの品質を確保するため、以下の優先度で調査を行う。

### 必須調査項目（必ず正確な情報を記載）

1. **基本情報**: ツール名、開発元、公式サイト、カテゴリ
2. **料金プラン**: 最新の料金情報、無料プランの有無
3. **主要機能**: 5項目以上
4. **セキュリティ**: 認証、データ管理、準拠規格

### 優先調査項目（可能な限り詳細に記載）

5. **ユーザーレビュー**: 2つ以上のソースから収集
6. **類似ツール比較**: 3つ以上のツールと比較
7. **直近のアップデート情報**: 6ヶ月以内の更新

### 補足調査項目

8. **導入実績**: 具体的な企業名
9. **サポート体制**: ドキュメント、コミュニティ、公式サポート
10. **エコシステムと連携**: API、外部連携、技術スタックとの相性

## 調査手順

### 1. 基本情報の収集

- 公式サイトから正確な情報を取得
- 開発元の企業情報を確認
- ツールのカテゴリと概要を明確に定義
- ツールの正確な読み方を確認（カタカナ。複数ある場合はその旨を記載）
- 常に最新の情報であることが絶対条件
  - 情報が古いものは更新情報を追加で調査
- 関連リンクの収集
  - GitHubリポジトリの有無を確認（オープンソースの場合）
  - 公式ドキュメントサイトのURLを収集（公式サイトと異なる場合）
  - 主要レビューサイト（G2, Capterra, ITreview等）のツールページURLを収集

### 2. 機能調査

- 公式ドキュメントから主要機能をリストアップ
- 機能の詳細と利用シーンを具体的に記述
- 最新の機能アップデートを確認

### 3. 料金・プラン調査

- 公式サイトの料金ページを詳細に確認
- 無料プランの制限事項を明記
- 各有料プランの対象ユーザーを明確化
- **表形式で整理すること**

### 4. ユーザーレビュー分析

以下のプラットフォームからレビューを収集・分析（最低2つ以上のソースから収集）：

| プラットフォーム | 対象 | 優先度 |
|---------------|------|-------|
| G2.com | BtoB SaaS | 必須 |
| Capterra | BtoB SaaS | 必須 |
| ITreview | 日本語レビュー | 推奨 |
| App Store | モバイルアプリ | 該当時のみ |
| Google Play | モバイルアプリ | 該当時のみ |
| X(Twitter) | 最新の評判 | 推奨 |
| Reddit | 技術系ツール | オプション |

**記載ルール:**
- 総合評価スコアがある場合は必ず記載（例: 4.5/5.0 (G2)）
- ポジティブ評価・ネガティブ評価を各3項目以上
- 具体的な引用や要約を含める

### 5. 競合分析

- 同カテゴリの主要な競合ツールを3-5個選定
- **機能比較表（星取表）の作成**:
  - **中立性**: 本ツールが勝っている機能だけでなく、競合ツールが優れている機能もリストアップする。どちらも公平に評価できる項目を選定する。
  - **客観性**: 記号（◎/◯/△/×）の基準を明確にする。
    - **◎**: 業界最高水準、独自の強み、カタログスペック以上
    - **◯**: 標準的に対応
    - **△**: 制限付き対応、要アドオン、少し弱い
    - **×**: 非対応
  - **双方向性の確認**: 既存のレポートがあるツールと比較する場合、そのレポートの記載内容と矛盾がないか確認する。
- **詳細比較表の作成**:
  - 定性的な違いや、具体的な利用シーンでの優劣を記述する。
- **重要**: 競合ツールの情報（バージョン、モデル名、主要機能、料金）が最新であることを必ず確認すること。特にAIツールの場合、モデル名（例: Claude 3.5 → 4.5）が更新されていないか重点的に調査する。

### 6. 最新情報の収集

- 公式ブログ、リリースノートから直近6ヶ月のアップデートを調査
  - 具体的なアップデート内容を記載（日付の降順、つまり新しいものが上になるように記載する）
  - 更新頻度が多い場合は代表的なものをピックアップ
- 今後のロードマップがあれば記載
- 業界トレンドとの関連性を分析

### 7. ツール評価の算出

基準点70点からの加減算方式で総合スコアを算出する。

**加点項目の例：**

| 項目 | 点数目安 | 説明 |
|-----|---------|------|
| 機能の充実度 | +3〜+10 | 競合より機能が豊富、独自機能がある |
| 日本語対応 | +3〜+5 | UI・ドキュメント・サポートの日本語対応 |
| 無料プランの充実 | +3〜+5 | 無料プランで十分な機能が使える |
| コストパフォーマンス | +3〜+5 | 機能に対して料金が安い |
| セキュリティ・認証 | +3〜+5 | SOC2、ISO27001等の取得 |
| 活発な開発・更新 | +2〜+5 | 頻繁なアップデート、ロードマップ公開 |
| ユーザー評価 | +2〜+5 | レビューサイトで高評価（4.5以上） |

**減点項目の例：**

| 項目 | 点数目安 | 説明 |
|-----|---------|------|
| 機能の不足 | -3〜-10 | 基本機能が欠けている、競合に劣る |
| 日本語非対応 | -3〜-5 | 日本語UI・サポートがない |
| 高コスト | -3〜-5 | 競合より料金が高い |
| セキュリティ懸念 | -3〜-10 | データ保管場所の問題、認証未取得 |
| 開発停滞 | -3〜-5 | アップデートが少ない、将来性に不安 |
| ユーザー評価低い | -3〜-5 | レビューサイトで低評価（3.5未満） |
| 学習コスト高い | -2〜-3 | 導入・習得に時間がかかる |

### 9. エコシステムと連携調査

- **API・外部サービス連携**:
  - APIの仕様とドキュメントの質を確認
  - 標準で連携可能なサービスをリストアップ
- **技術スタックとの相性調査**:
  - **表形式で作成**: 主要な3-5個の技術スタック（フレームワーク、言語、プラットフォーム）を選定し、比較表を作成する。
  - **評価基準**:
    - **◎ (非常に良い)**: 公式SDK/Pluginが提供されており、ドキュメントも充実している。ファーストクラスサポート。
    - **◯ (良い)**: 公式または信頼できるコミュニティライブラリがあり、標準的な利用が可能。
    - **△ (工夫が必要)**: 利用は可能だが、設定が複雑、または公式サポートがない（コミュニティ依存）。
    - **× (非推奨/非対応)**: SDKがなく、APIを直接実装する必要がある、または既知の重大な非互換性がある。
  - **調査項目**:
    - **公式SDK**: どの言語・フレームワーク向けに公式SDKが提供されているか確認。
    - **クイックスタート**: 特定技術向けのガイド有無。
    - **コミュニティの知見**: 実際の開発者の声（Qiita, Zenn, StackOverflow）から、ハマりポイント（懸念点）を抽出。

### 10. 関連ツールの更新 (双方向性)

本レポートの調査過程で、競合ツールや関連ツールに関する新しい事実や更新情報が見つかった場合、以下の手順を実行する。

1. **既存レポートの確認**: `_reports/` ディレクトリ内に、比較対象としたツールのレポートが存在するか確認する。
2. **情報の整合性チェック**:
   - 今回の調査で判明した事実（例: ツールAはSSOに対応している）と、既存のツールAのレポート内容に矛盾がないか確認する。
   - **星取表の更新**: 既存レポートの星取表において、機能の有無や評価が古い場合は更新する。
3. **関連レポートの更新**:
   - 情報が古い、または誤っている場合は、そのツールのレポートも併せて更新する（`last_updated`の日付も更新）。
   - これにより、サイト全体の情報の整合性と鮮度を保つ。


## 調査時の注意点

### 情報の信頼性

- 公式情報を最優先とする
- 第三者レビューは複数ソースから収集
- 情報の更新日時を確認し、古い情報は避ける
- 調査時に情報の出典元のリンクを貼る

**日付・バージョン・リリース情報の検証（必須）:**
- **リリース日・発表日は必ず公式情報源から確認すること**
  - 公式ブログ、公式プレスリリース、公式ドキュメントのリリースノートを優先参照
  - ニュース記事や第三者サイトの情報のみでは記載しない
- **バージョン番号・モデル名は公式発表と正確に一致させること**
  - 例: 「Gemini 2.5 Pro」と「Gemini 3 Pro」は異なるモデル
  - **競合ツールのモデル名も同様に最新化すること**（例: ChatGPT-4o, Claude 3.5 Sonnetなど）
  - 曖昧な場合は記載を見送り、確認済みの事実のみを記載する
- **複数の情報源で日付が異なる場合**
  - 公式情報源（公式ブログ、プレスリリース）を最優先
  - 確認が取れない場合は「公式発表によると」など出典を明記する
- **将来の日付や未発表情報について**
  - 噂やリーク情報は記載しない
  - ロードマップに記載がある場合はその旨を明記する

**リンク切れの確認:**
- **必須**: `python3 scripts/check_links.py [ファイルパス]` を実行し、リンク切れ（404エラー）がないことを確認する
- 記載する全URLについて、ブラウザ等でアクセスし、ページが存在することを確認する
- 「Page Not Found (404)」となるリンクは記載しない

**レビューサイトリンクの検証:**

G2、Capterra等のレビューサイトはボット検出が厳しく、自動チェックでは403（アクセス拒否）となることが多い。以下の手順で対応すること：

| ステータス | 対応方法 |
|-----------|---------|
| 200 OK | 正常。そのまま記載可 |
| 404 Not Found | リンク切れ。記載しない |
| 403 Forbidden | 以下の追加検証を実施 |

**403エラー時の追加検証手順:**

1. **Google検索で存在確認**: `site:g2.com "[ツール名]"` または `site:capterra.com "[ツール名]"` で検索
2. **検索結果からURLを取得**: 検索結果に表示されるURLを確認し、正確なURLを記載
3. **ページの実在性を確認**: 検索結果のスニペットにツール名やレビュー情報が含まれていれば実在と判断
4. **存在しない場合**: レビューサイトへのリンクは記載せず、「基本情報 > 関連リンク > レビューサイト」の項目自体を省略する

**レビューサイトへのリンクが記載できない場合の代替:**

レビューサイトへの直接リンクが記載できない場合でも、「12. ユーザーの声」セクションでレビュー情報は必須である。以下の方法で情報を収集・引用すること：

- Google検索で `"[ツール名]" site:g2.com レビュー` 等で検索し、スニペットから評価スコアやレビュー内容を引用
- 検索結果で表示される情報を「（G2より引用）」「（Capterraより引用）」等、出典を明記して記載
- 他の信頼できる情報源（Tech系メディアのレビュー記事、公式サイトの testimonials 等）も活用する

### 「情報が見つからない」場合の記載ルール

情報が見つからない場合、「不明」「見つからず」のみの記載は避け、以下のように記載する：

| 状況 | 記載例 |
|-----|-------|
| 公式サイトに記載なし | 「公式サイトでは公開されていない。個別の問い合わせが必要。」 |
| 調査したが情報なし | 「G2、Capterra、ITreviewにレビューの登録なし。」 |
| 新しいサービスで実績なし | 「2024年リリースの新サービスのため、公開事例はまだ少ない。」 |

### 日本語対応の確認

- UIの日本語化状況
- 日本語サポートの有無
- 日本国内での導入実績

### セキュリティ・コンプライアンス

- データの保存場所（国内/海外）
- 主要な認証取得状況
- プライバシーポリシーの内容

## レポート作成のガイドライン

### 文体・表現

- 客観的で中立的な表現を使用
- 具体的な数値やデータを可能な限り記載
- 推測や憶測は避け、事実に基づいた記述

### 構成

- **テンプレート（`templates/template.md`）の構成に厳密に従って作成**
  - セクションの追加・削除・順序変更は禁止
  - 各セクション内のガイドラインコメントに従う
  - 料金プラン・類似ツール比較は表形式を使用
- 各セクションは簡潔かつ包括的に記載
- 読み手が意思決定に必要な情報を網羅

### ファイル命名規則

- ファイル名: `_reports/[ツール名].md`
- 日本語ツール名の場合は英語表記も併記
- 特殊文字は避け、ハイフンで区切る

### フロントマター

レポートファイルの先頭に以下のフロントマターを必ず付与する。

```yaml
---
# 【必須項目】
title: "[ツール名] 調査レポート"
tool_name: "ツール名"
tool_reading: "ツールの読み方"  # カタカナ。必須。複数ある場合は「 A / B 」のように併記
category: "カテゴリ名"
developer: "開発元企業名"
official_site: "公式サイトURL"
date: "YYYY-MM-DD" (作成日)
last_updated: "YYYY-MM-DD" (更新日)
tags:
  - "タグ1"
  - "タグ2"
  - "タグ3"
description: "ツールの概要を1-2行で簡潔に記述"

# 【クイックサマリー】ホーム画面のカード表示用
quick_summary:
  has_free_plan: true  # 無料プランの有無
  starting_price: "$10/月"  # 最低価格
  target_users:
    - "開発者"
    - "スタートアップ"
  latest_highlight: "直近1ヶ月の注目アップデート"
  update_frequency: "高"  # 高/中/低/不定期

# 【ツール評価】100点満点、基準点70点からの加減算方式
evaluation:
  score: 75  # 最終スコア（0-100点）
  base_score: 70  # 基準点（固定）
  plus_points:  # 加点項目
    - point: 5
      reason: "機能が豊富で競合より優れている"
  minus_points:  # 減点項目
    - point: -3
      reason: "料金が競合より高め"
  summary: "機能面では優れているが、コスト面での検討が必要"

# 【任意項目】該当するもののみ記載
links:
  github: "GitHubリポジトリURL"
  documentation: "ドキュメントサイトURL"
relationships:
  parent: "親ツールのツール名"
  children:
    - "子ツールのツール名"
  related_tools:
    - "関連ツールのツール名"
---
```

**フロントマター記入時の注意点：**

- `date`: レポート作成日（日本時間）
- `tool_reading`: ツールの正確なカタカナ読み。**必須項目**。複数ある場合は「 A / B 」のように併記する
- `last_updated`: 最終更新日（日本時間）
- `tags`: ツールの特徴を表すタグ（例: "CI/CD", "オープンソース", "クラウド"）
- `description`: 検索やインデックス用の簡潔なツールの説明
  - 「〜に関するレポートです」「〜の調査レポート」などの表現は使用しない
  - ツール自体の機能や特徴を直接説明する（例: "高性能なAIコーディングエージェント"）
  - ツールが解決する課題や提供する価値を簡潔に記述する
- `quick_summary`: ホーム画面のカード表示用のサマリー情報
  - `has_free_plan`: 無料プランの有無（true/false）
  - `starting_price`: 最低価格（例: "$10/月"、"¥1,000/月"、"無料"）
  - `target_users`: 想定ユーザー（1-3項目。例: "開発者", "スタートアップ", "大企業"）
  - `latest_highlight`: 直近1ヶ月の注目アップデート（1文で簡潔に）
  - `update_frequency`: 更新頻度（"高"/"中"/"低"/"不定期"）
- `evaluation`: ツール評価（100点満点、基準点70点からの加減算方式）
  - `score`: 最終スコア（0-100点）。base_score + plus_points - minus_points で算出
  - `base_score`: 基準点（常に70点）
  - `plus_points`: 加点項目。各項目に`point`（加点する点数）と`reason`（理由）を記載
  - `minus_points`: 減点項目。各項目に`point`（減点する点数、マイナス値）と`reason`（理由）を記載
  - `summary`: 評価の要約（1文）
- `links`: 関連リンクを記載（該当するもののみ）
  - `github`: オープンソースツールの場合、GitHubリポジトリURL
  - `documentation`: 公式ドキュメントサイトURL（公式サイトと異なる場合）
  - 該当しない項目は省略可能
- `relationships`: 関連するツールがあれば記載する。
  - **重要**: `_reports/`ディレクトリにレポートファイルが存在しないツールは記載してはならない。
  - `tool_name`は正確に一致させること。

### 成果物の管理

- **テストコードの除外**: テストや検証に使用したPythonスクリプト（`verify_*.py`など）はコミットしないこと。
- **キャプチャ画像の除外**: 検証時に取得した画面キャプチャ画像はコミットしないこと。
- **一時ファイルの削除**: その他、不要な一時ファイルはコミット前に削除するか、`.gitignore`で除外されていることを確認する。

## 品質基準

レポートの品質を以下の基準で評価する：

| 項目 | 最低要件 | 推奨 |
|-----|---------|-----|
| フロントマター | 必須項目がすべて記載 | 任意項目も可能な限り記載 |
| 基本情報 | 公式サイトURL、開発元、カテゴリが正確 | 関連リンクも含む |
| 主要機能 | 5項目以上 | 10項目程度 |
| 料金プラン | 表形式で最新情報 | 課金体系の詳細説明も含む |
| ユーザーレビュー | 1ソース以上 | 2ソース以上、評価スコア記載 |
| 類似ツール比較 | 2ツール以上を表形式で比較 | 3-5ツールを詳細に比較 |
| セキュリティ | 認証・データ管理を記載 | 準拠規格も含む |
| アップデート情報 | 3項目以上 | 6ヶ月分を網羅 |

## 調査完了後のチェックリスト

### 必須チェック

- [ ] テンプレート（`templates/template.md`）の構成に従っている
- [ ] フロントマターの必須項目がすべて記載されている
- [ ] `tool_reading`（ツールの読み方）が記載されている
- [ ] 全15セクションが埋められている
- [ ] 料金プランが表形式で記載されている
- [ ] 類似ツール比較が「機能比較表（星取表）」と「詳細比較」で構成されている
- [ ] セキュリティ情報が「不明」のみで済まされていない
- [ ] リンク切れがない（`python scripts/check_links.py` で確認）

### 品質チェック

- [ ] 公式情報の正確性を確認済み
- [ ] 複数のレビューソースから情報を収集済み
- [ ] 競合ツールとの比較が適切である（星取表の中立性）
- [ ] 関連・競合ツールの既存レポートとの整合性を確認・更新済み（双方向性）
- [ ] 日本語対応状況が明記されている
- [ ] 総評が客観的で有用である

### 成果物チェック

- [ ] テストコードや検証用画像がコミットに含まれていない

## 更新・メンテナンス

- 大きな機能アップデートがあった場合は随時更新
- ユーザーからのフィードバックを反映
- **テンプレートが更新された場合は、既存レポートもテンプレートに合わせて更新する**

---

**注意**
このガイドラインに従って調査を行い、質の高いレポートを作成する。不明な点がある場合は、可能な限り公式情報を参照し、推測ではなく事実に基づいた記述を心がける。
テンプレート(`templates/template.md`)から項目名や記載内容がずれている場合はテンプレートに合わせて更新する。
