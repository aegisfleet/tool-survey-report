---
# 【必須項目】
title: "UI-TARS Desktop 調査レポート"
tool_name: "UI-TARS Desktop"
tool_reading: "ユーアイターズ デスクトップ"
category: "自律型AIエージェント"
developer: "ByteDance"
official_site: "https://github.com/bytedance/UI-TARS-desktop"
date: "2026-02-06"
last_updated: "2026-02-06"
tags:
  - "AI"
  - "エージェント"
  - "自律型"
  - "オープンソース"
  - "GUI"
  - "デスクトップ操作"
  - "ByteDance"
description: "VLMを活用し、人間のようにPC画面を見て操作する自律型GUIエージェント。アクセシビリティツリーと視覚情報の両方を利用して高精度な操作を実現。"

# 【クイックサマリー】ホーム画面のカード表示用
quick_summary:
  has_free_plan: true
  is_oss: true
  starting_price: "無料"
  target_users:
    - "開発者"
    - "AI研究者"
    - "自動化エンジニア"
  latest_highlight: "2025年1月に論文公開、デスクトップアプリとしてリリース"
  update_frequency: "高"

# 【ツール評価】100点満点、基準点70点からの加減算方式
evaluation:
  score: 82
  base_score: 70
  plus_points:
    - point: 5
      reason: "完全にローカル環境（Ollama/vLLM）で動作可能"
    - point: 5
      reason: "視覚情報とアクセシビリティツリーを組み合わせた高精度な操作"
    - point: 5
      reason: "オープンソース（Apache 2.0）でカスタマイズ性が高い"
  minus_points:
    - point: -3
      reason: "セットアップにはある程度の技術的知識（環境構築）が必要"
  summary: "ローカルで動作する高性能なGUIエージェントとして、プライバシーやコストを重視するユーザーに最適。"

# 【任意項目】該当するもののみ記載
links:
  github: "https://github.com/bytedance/UI-TARS-desktop"
  documentation: "https://github.com/bytedance/UI-TARS-desktop/tree/main/docs"
relationships:
  parent: null
  children: []
  related_tools:
    - "Claude"
    - "OpenHands"
    - "Ollama"
    - "Hugging Face"
---

# **UI-TARS Desktop 調査レポート**

## **1. 基本情報**

<!--
【ガイドライン】
- 必須: ツール名、開発元、公式サイト、カテゴリ、概要
- 概要は2-3文で簡潔に記述
-->

* **ツール名**: UI-TARS Desktop
* **ツールの読み方**: ユーアイターズ デスクトップ
* **開発元**: ByteDance
* **公式サイト**: [https://github.com/bytedance/UI-TARS-desktop](https://github.com/bytedance/UI-TARS-desktop)
* **関連リンク**:
  * モデルリポジトリ: [https://github.com/bytedance/UI-TARS](https://github.com/bytedance/UI-TARS)
  * 論文 (arXiv): [UI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/abs/2501.12326)
* **カテゴリ**: 自律型AIエージェント, 自動化ツール
* **概要**: ByteDanceが開発した「UI-TARS」モデルをベースにした、デスクトップ操作用の自律型AIエージェントアプリケーション。Vision-Language Model (VLM) を活用し、人間のように画面を見てクリックや入力を行うことができ、アクセシビリティツリーの情報も併用することで高い操作精度を実現している。Windows、macOS、Linuxで動作する。

## **2. 目的と主な利用シーン**

<!--
【ガイドライン】
- 3-5項目を箇条書きで記述
- 想定利用者を具体的に記載
-->

* **解決する課題**: 従来のRPAでは対応が難しい動的なUI操作や、APIがないアプリケーションの自動操作。また、クラウド型エージェント利用時のプライバシー懸念やコストの問題。
* **想定利用者**: 開発者, 自動化エンジニア, AI研究者
* **利用シーン**:
  * 複雑なWebブラウザ操作の自動化（検索、予約、データ収集）
  * デスクトップアプリケーションの操作自動化
  * OS設定の変更やファイル操作などの定型業務の代行
  * アクセシビリティテストやUIテストの自動化

## **3. 主要機能**

<!--
【ガイドライン】
- 5-10項目の主要機能を箇条書きで記述
- 各機能は1-2文で概要を説明
-->

* **ネイティブGUI操作**: マウス移動、クリック、ドラッグ＆ドロップ、キーボード入力など、人間と同様の操作をエミュレートする。
* **ハイブリッド認識**: スクリーンショット（視覚情報）とアクセシビリティツリー（構造情報）の両方を活用し、UI要素を正確に特定する。
* **ローカルモデル対応**: OllamaやvLLMバックエンドをサポートし、ローカル環境でモデルを動かすことでプライバシーを保護しつつ利用可能。
* **マルチプラットフォーム**: Windows, macOS, Linux (Docker) で動作し、クロスプラットフォームな操作が可能。
* **リモートデスクトップ操作**: ローカルマシンだけでなく、リモート環境のブラウザやデスクトップも操作可能。
* **柔軟なモデル選択**: 自社のUI-TARSモデル（Doubaoベースなど）だけでなく、Hugging Face上のモデルやOpenAI互換APIを持つモデルとも連携可能。

## **4. 特徴・強み (Pros)**

<!--
【ガイドライン】
- 3-5項目を箇条書きで記述
- 競合との差別化ポイントを明確に
-->

* **完全ローカル実行**: 外部クラウドに画面データを送信せず、ローカルLLMで完結させることが可能（セキュリティ面での強み）。
* **高い要素特定能力**: 単なる画像認識だけでなく、OSのアクセシビリティ情報を利用するため、ボタンや入力フォームの特定が正確。
* **オープンソース**: Apache 2.0ライセンスで公開されており、企業内でのカスタマイズや組み込みが容易。
* **コスト効率**: API課金が発生するクラウド型サービス（Claude Computer Useなど）と異なり、ローカル実行ならランニングコストは電気代のみ。

## **5. 弱み・注意点 (Cons)**

<!--
【ガイドライン】
- 3-5項目を箇条書きで記述
- 日本語対応の状況は必ず含める
-->

* **環境構築のハードル**: ローカルで快適に動作させるには、高性能なGPUやメモリ、Ollama/vLLMのセットアップが必要。
* **実行速度**: クラウド上の超高速なモデルに比べ、ローカル環境のスペックによっては推論に時間がかかる場合がある。
* **モデルの成熟度**: 2025年1月リリースの比較的新しいプロジェクトであり、エコシステムやコミュニティの知見は発展途上。
* **日本語対応**: UI自体は多言語対応が進んでいるが、ドキュメントやプロンプトの調整が必要な場合がある（基本は英語/中国語中心）。

## **6. 料金プラン**

<!--
【ガイドライン】
- 表形式で整理することを推奨
- 最新の料金情報であることを確認
- 価格は通貨を明記（例: $10/月、¥1,000/月）
-->

| プラン名 | 料金 | 主な特徴 |
|---|---|---|
| **オープンソース版** | 無料 | GitHubからソースコードまたはバイナリを入手可能。自前でモデルをホストする必要あり。 |

* **課金体系**: ソフトウェア自体は無料。APIを利用する場合（例：VolcEngineなど）は別途モデル利用料が発生。

## **7. 導入実績・事例**

<!--
【ガイドライン】
- 具体的な企業名を3-5社挙げる
- 導入事例がない場合は「公開事例なし。ただし、〜の分野での利用が報告されている」等
-->

* **導入企業**: ByteDance（開発元）での社内利用や実証実験が主と考えられる。
* **導入事例**: 2025年リリースのため、公開された第三者の大規模導入事例はまだ少ないが、GitHubでのStar数は急速に伸びており、個人の開発者や研究者による試用報告が多い。

## **8. サポート体制**

<!--
【ガイドライン】
- ドキュメント、コミュニティ、公式サポートの3項目を必ず含める
- URLがあれば記載
-->

* **ドキュメント**: GitHubリポジトリ内の `docs/` にセットアップガイドや設定例が含まれている。
* **コミュニティ**: GitHub IssuesやDiscussionsでのやり取りが活発。
* **公式サポート**: オープンソースプロジェクトのため、商用サポートは提供されていない（コミュニティベース）。

## **9. エコシステムと連携**

<!--
【ガイドライン】
- API、外部連携、技術スタックとの相性を包括的に記述
-->

### **9.1 API・外部サービス連携**

<!--
【ガイドライン】
- APIの有無と公開状況を明記
- 主要連携サービスを5-10個リストアップ
-->

* **モデルプロバイダ**: Ollama, vLLM, Hugging Face, VolcEngine (Doubao) と連携可能。
* **API互換性**: OpenAI互換のAPIエンドポイントを持つバックエンドであれば接続可能。

### **9.2 技術スタックとの相性**

<!--
【ガイドライン】
- 主要なフレームワークや言語との相性を表形式で整理
- 相性: ◎ (非常に良い), ◯ (良い), △ (工夫が必要/一部非対応), × (非推奨)
-->

| 技術スタック | 相性 | メリット・推奨理由 | 懸念点・注意点 |
|:---|:---:|:---|:---|
| **Python** | ◎ | モデルのバックエンドやスクリプトはPythonで記述されており、拡張が容易。 | 特になし。 |
| **Electron** | ◎ | デスクトップアプリ自体がElectronベースで開発されているため、フロントエンド技術でカスタマイズ可能。 | 特になし。 |
| **Docker** | ◯ | Dockerコンテナ内での実行もサポートされており、環境分離が容易。 | GPUパススルーの設定が必要。 |

## **10. セキュリティとコンプライアンス**

<!--
【ガイドライン】
- 認証、データ管理、準拠規格の3項目を必ず調査
- 情報が見つからない場合は「公式サイトで公開されていない。問い合わせが必要。」と記載
- 「不明」「見つからず」のみの記載は避ける
-->

* **データ管理**: ローカルモデルを使用する場合、スクリーンショットや操作ログは外部に送信されず、完全にローカルマシン内で処理されるため、機密情報の取り扱いに適している。
* **認証**: デスクトップアプリ自体にはユーザー認証機能はない（OSのログインに依存）。
* **準拠規格**: 特に明記なし。オープンソースソフトウェアとしての提供。

## **11. 操作性 (UI/UX) と学習コスト**

<!--
【ガイドライン】
- 実際の使用感や、類似ツールとの比較を含める
-->

* **UI/UX**: モダンなチャットインターフェースを備え、指示を入力するとエージェントが画面操作を開始する。操作内容はリアルタイムで確認可能。
* **学習コスト**: アプリの操作自体はシンプルだが、バックエンド（Ollama等）の適切なモデル設定やプロンプトエンジニアリングには一定の知識が必要。

## **12. ベストプラクティス**

<!--
【ガイドライン】
- ツールを効果的に活用するための推奨事項や、避けるべきアンチパターンを記述
- 公式ドキュメントのBest Practicesや、熟練エンジニアの知見を参考にする
-->

* **Modern Practices**:
  * **適切なモデルの選択**: タスクの難易度に応じて、軽量なローカルモデルか、高精度なクラウドモデル（API経由）を使い分ける。
  * **具体的な指示**: 「メールを送って」ではなく「Gmailを開いて、宛先X、件名Yで本文Zのメールを作成して送信して」のように具体的かつ手順を追って指示する。
* **Anti-patterns**:
  * **複雑すぎる指示の丸投げ**: 抽象度が高すぎるタスクは失敗しやすいため、サブタスクに分解せずに一度に依頼することは避ける。
  * **スクリーンショットのみへの依存**: アクセシビリティツリーが利用可能な場合は、視覚情報だけに頼らない設定を確認する。

## **13. ユーザーの声（レビュー分析）**

<!--
【ガイドライン】
- 必須調査サイト: G2, Capterra, ITreview（日本語レビュー）のうち該当するもの
- 追加調査サイト: App Store, Google Play, X(Twitter), Reddit等
- 総合評価スコアがあれば必ず記載
- ポジティブ・ネガティブ各3項目以上
-->

* **調査対象**: GitHub Star数、X (Twitter)、Reddit
* **総合評価**: リリース直後から数千スターを獲得し、注目度は非常に高い。
* **ポジティブな評価**:
  * 「ClaudeのComputer Useをローカルで再現できるのが素晴らしい」
  * 「無料で使えるGUIエージェントとして期待大」
  * 「セットアップが比較的簡単（Dockerやインストーラがあるため）」
* **ネガティブな評価 / 改善要望**:
  * 「まだ動作が不安定な場合がある」
  * 「対応しているモデルが重く、ハイスペックなPCが必要」
  * 「日本語入力周りでトラブルが起きることがある」

## **14. 直近半年のアップデート情報**

<!--
【ガイドライン】
- 日付の降順（新しいものが上）
- 3-10項目をリストアップ
- 各項目に日付と概要を含める
- 情報源のURLを記載
-->

* **2025-01-22**: arXivにて論文「UI-TARS: Pioneering Automated GUI Interaction with Native Agents」が公開。
* **2025-01**: GitHubにて `UI-TARS` および `UI-TARS-desktop` リポジトリが公開・開発開始。
* **2025-01**: 初期バージョン v0.1 リリース。macOS, Windows版のインストーラ提供開始。

(出典: [GitHub Releases](https://github.com/bytedance/UI-TARS-desktop/releases), [arXiv](https://arxiv.org/abs/2501.12326))

## **15. 類似ツールとの比較**

<!--
【ガイドライン】
- 3-5個の類似ツールと比較
- **機能比較表（星取表）**と**詳細比較**の2つの観点で記述する
-->

### **15.1 機能比較表 (星取表)**

| 機能カテゴリ | 機能項目 | 本ツール (UI-TARS) | Claude (Computer Use) | OpenHands | OmniParser |
|:---:|:---|:---:|:---:|:---:|:---:|
| **実行環境** | ローカル実行 | ◎<br><small>完全対応</small> | ×<br><small>APIのみ</small> | ◯<br><small>Docker等</small> | ◯<br><small>モデルのみ</small> |
| **操作対象** | ネイティブアプリ | ◎<br><small>OS全体</small> | ◯<br><small>仮想環境推奨</small> | △<br><small>ブラウザ中心</small> | -<br><small>解析のみ</small> |
| **コスト** | 利用料 | ◎<br><small>無料 (OSS)</small> | △<br><small>従量課金</small> | ◎<br><small>無料 (OSS)</small> | ◎<br><small>無料 (OSS)</small> |
| **認識技術** | ハイブリッド認識 | ◎<br><small>Vision + Accessibility</small> | ◯<br><small>Vision中心</small> | ◯<br><small>各種</small> | ◎<br><small>Vision解析特化</small> |

### **15.2 詳細比較**

| ツール名 | 特徴 | 強み | 弱み | 選択肢となるケース |
|---------|------|------|------|------------------|
| **UI-TARS** | ByteDance発のネイティブGUIエージェント。視覚と構造情報の両方を利用。 | ローカルで動作し、プライバシーとコストに優れる。OS全体の操作が可能。 | ハイスペックなローカルマシンが必要。発展途上。 | コストを抑えたい、ローカルで完結させたい、OS操作を行いたい場合。 |
| **Claude** | AnthropicのComputer Use機能。API経由でスクリーンショットを送り操作指示を受け取る。 | モデルの推論能力が非常に高く、複雑なタスクの計画能力に優れる。 | APIコストがかかる。画面データを送信する必要がある。 | 最高精度の推論が必要で、クラウド利用が許容される場合。 |
| **OpenHands** | オープンソースの自律型開発エージェント。旧OpenDevin。 | 開発タスク（コーディング、コマンド実行）に特化しており、コミュニティが活発。 | 一般的なGUI操作（ExcelやOS設定など）よりは、開発環境の操作がメイン。 | ソフトウェア開発の自動化を目的とする場合。 |
| **OmniParser** | Microsoftの画面解析モデル。スクリーンショットからUI要素を構造化データに変換。 | UI要素の検出・解析精度が非常に高い。 | これ自体は「エージェント」ではなく「目」の役割。操作機能はない。 | 自作のエージェントに画面認識機能を組み込みたい場合。 |

## **16. 総評**

<!--
【ガイドライン】
- 総合評価、推奨チーム、選択ポイントの3項目を必ず含める
- 客観的で中立的な評価を心がける
-->

* **総合的な評価**:
  UI-TARS Desktopは、急速に進化する「GUIエージェント」の分野において、**完全ローカル実行が可能**かつ**実用的なネイティブアプリ**として提供されている点で画期的である。特に、視覚情報だけでなくOSのアクセシビリティツリーを活用するアプローチは、純粋なVisionモデルよりも操作の確実性が高く、RPAの代替や個人の作業自動化アシスタントとして大きな可能性を秘めている。
* **推奨されるチームやプロジェクト**:
  プライバシーコンプライアンスが厳しく外部への画面データ送信が難しい企業や、APIコストを気にせず常時稼働させたい自動化プロジェクトに推奨される。
* **選択時のポイント**:
  「セットアップの手軽さと最高精度の推論」を求めるならClaude Computer Useが勝るが、「ランニングコストの安さ」「ローカル完結の安心感」「OSSとしての拡張性」を重視するならUI-TARSが最適な選択肢となる。
